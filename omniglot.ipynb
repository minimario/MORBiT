{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd0c842eb500ccb71b64d518eca64d0d25bbe17d781a8339fe0a329310a99fe2a90",
   "display_name": "Python 3.7.10 64-bit ('bilevel': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "c842eb500ccb71b64d518eca64d0d25bbe17d781a8339fe0a329310a99fe2a90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "train_dir = \"/home/minimario/Documents/bilevel/new/data/omniglot_resized/images_background\"\n",
    "eval_dir = \"/home/minimario/Documents/bilevel/new/data/omniglot_resized/images_evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "g = glob(f\"{train_dir}/*\")\n",
    "alphabets = []\n",
    "for alphabet in g:\n",
    "    alphabets.append(alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_image(infilename) :\n",
    "    img = Image.open( infilename )\n",
    "    img.load()\n",
    "    data = np.asarray( img, dtype=\"int32\" )\n",
    "    return data\n",
    "\n",
    "def save_image( npdata, outfilename ) :\n",
    "    img = Image.fromarray( np.asarray( np.clip(npdata,0,255), dtype=\"uint8\"), \"L\" )\n",
    "    img.save( outfilename )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "def sample_batch(alphabet_index, ways, shots):\n",
    "    alphabet_dir = alphabets[alphabet_index]\n",
    "    g = glob(f\"{alphabet_dir}/*\")\n",
    "    num_characters = len(g)\n",
    "    indices = np.random.choice(num_characters, ways, replace=False)\n",
    "\n",
    "    train_xs = np.zeros((ways*shots, 1, 28, 28))    \n",
    "    train_ys = np.zeros((ways*shots), dtype=np.int)\n",
    "\n",
    "    ct = 0\n",
    "    for i in range(len(indices)):\n",
    "        index = indices[i]\n",
    "        path = g[index]\n",
    "        s = random.sample(os.listdir(path), 2*shots)\n",
    "        for j in range(shots):\n",
    "            image = f\"{path}/{s[j]}\"\n",
    "            img = load_image(image)\n",
    "            train_xs[ct][0] = img\n",
    "            train_ys[ct] = index\n",
    "            ct += 1\n",
    "\n",
    "    return torch.tensor(train_xs, dtype=torch.float32), torch.tensor(train_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import learn2learn as l2l\n",
    "from torch import nn\n",
    "\n",
    "def get_alphabet_length(i):\n",
    "    return len(glob(f\"{alphabets[i]}/*\"))\n",
    "\n",
    "class Lambda(nn.Module):\n",
    "\n",
    "    def __init__(self, fn):\n",
    "        super(Lambda, self).__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fn(x)\n",
    "\n",
    "ways = 3\n",
    "shots = 5\n",
    "features = l2l.vision.models.ConvBase(output_size=64, channels=1, max_pool=True)\n",
    "features = torch.nn.Sequential(features, Lambda(lambda x: x.view(-1, 64)))\n",
    "\n",
    "heads = [torch.nn.Linear(64, get_alphabet_length(i)) for i in range(len(alphabets))]\n",
    "feature_optimizers = torch.optim.Adam(list(features.parameters()))\n",
    "head_optimizers = [torch.optim.Adam(list(heads[i].parameters())) for i in range(len(alphabets))]\n",
    "\n",
    "# head.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.25 0.75]\n"
     ]
    }
   ],
   "source": [
    "def simplex_projection(s):\n",
    "    \"\"\"Projection onto the unit simplex.\"\"\"\n",
    "    if np.sum(s) <=1 and np.alltrue(s >= 0):\n",
    "        return s\n",
    "    # Code taken from https://gist.github.com/daien/1272551\n",
    "    # get the array of cumulative sums of a sorted (decreasing) copy of v\n",
    "    u = np.sort(s)[::-1]\n",
    "    cssv = np.cumsum(u)\n",
    "    # get the number of > 0 components of the optimal solution\n",
    "    rho = np.nonzero(u * np.arange(1, len(u)+1) > (cssv - 1))[0][-1]\n",
    "    # compute the Lagrange multiplier associated to the simplex constraint\n",
    "    theta = (cssv[rho] - 1) / (rho + 1.0)\n",
    "    # compute the projection by thresholding v using theta\n",
    "    return np.maximum(s-theta, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/minimario/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "tensor(0.5218, grad_fn=<AddBackward0>)\n",
      "tensor(0.5910, grad_fn=<AddBackward0>)\n",
      "tensor(0.4812, grad_fn=<AddBackward0>)\n",
      "tensor(0.2751, grad_fn=<AddBackward0>)\n",
      "tensor(0.5118, grad_fn=<AddBackward0>)\n",
      "tensor(0.6790, grad_fn=<AddBackward0>)\n",
      "tensor(0.2421, grad_fn=<AddBackward0>)\n",
      "tensor(0.7569, grad_fn=<AddBackward0>)\n",
      "tensor(0.5509, grad_fn=<AddBackward0>)\n",
      "tensor(0.6437, grad_fn=<AddBackward0>)\n",
      "tensor(0.3626, grad_fn=<AddBackward0>)\n",
      "tensor(0.5408, grad_fn=<AddBackward0>)\n",
      "tensor(0.5360, grad_fn=<AddBackward0>)\n",
      "tensor(0.6697, grad_fn=<AddBackward0>)\n",
      "tensor(0.3096, grad_fn=<AddBackward0>)\n",
      "tensor(0.8844, grad_fn=<AddBackward0>)\n",
      "tensor(0.9018, grad_fn=<AddBackward0>)\n",
      "tensor(0.8423, grad_fn=<AddBackward0>)\n",
      "tensor(0.7369, grad_fn=<AddBackward0>)\n",
      "tensor(0.8554, grad_fn=<AddBackward0>)\n",
      "tensor(0.6979, grad_fn=<AddBackward0>)\n",
      "tensor(0.5471, grad_fn=<AddBackward0>)\n",
      "tensor(0.1658, grad_fn=<AddBackward0>)\n",
      "tensor(0.0011, grad_fn=<AddBackward0>)\n",
      "tensor(0.5146, grad_fn=<AddBackward0>)\n",
      "tensor(0.1945, grad_fn=<AddBackward0>)\n",
      "tensor(0.6985, grad_fn=<AddBackward0>)\n",
      "tensor(0.2016, grad_fn=<AddBackward0>)\n",
      "tensor(0.9311, grad_fn=<AddBackward0>)\n",
      "tensor(0.6756, grad_fn=<AddBackward0>)\n",
      "tensor(0.7289, grad_fn=<AddBackward0>)\n",
      "tensor(0.1986, grad_fn=<AddBackward0>)\n",
      "tensor(0.4325, grad_fn=<AddBackward0>)\n",
      "tensor(0.1891, grad_fn=<AddBackward0>)\n",
      "tensor(0.4036, grad_fn=<AddBackward0>)\n",
      "tensor(0.2952, grad_fn=<AddBackward0>)\n",
      "tensor(1.1089, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-546d8bfc26d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mlambda_update\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minner_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mfeature_optimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mlambdas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplex_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambdas\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlambda_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# All strings are unicode in Python 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m    356\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m                     \u001b[0mtensor_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bilevel/lib/python3.7/site-packages/torch/_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0mnonzero_finite_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_view\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mtensor_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnonzero_finite_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_iterations = 10000\n",
    "n_inner = 10\n",
    "ways = 3\n",
    "shots = 5\n",
    "loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "lambdas = 1/30 * np.ones(30)\n",
    "gamma = 0.01\n",
    "for it_outer in range(n_iterations):\n",
    "    # sample some # of alphabets\n",
    "    alphabet_indices = np.random.choice(len(alphabets), 5, replace=False)\n",
    "    # alphabet_indices = np.random.choice(5, 5, replace=False)\n",
    "\n",
    "    # inner loop\n",
    "    # print(\"inner loop started\")\n",
    "    for it_inner in range(n_inner):\n",
    "        a = alphabet_indices[it_inner%5]\n",
    "        xs, ys = sample_batch(a, ways, shots)\n",
    "        outer_loop = features(xs)\n",
    "        inner_loop = heads[a](outer_loop) # [15 (ways * shots), length of alphabet]\n",
    "        total_loss = loss(inner_loop, ys)\n",
    "        total_loss.backward()\n",
    "        head_optimizers[a].step()\n",
    "    # print(\"inner loop done\")\n",
    "\n",
    "    # outer update\n",
    "    # print(\"outer loop started\")\n",
    "    a = alphabet_indices[it_inner%5]\n",
    "    total_loss = 0\n",
    "    lambda_update = np.zeros(30,)\n",
    "    for a in alphabet_indices:\n",
    "        xs, ys = sample_batch(a, ways, shots)\n",
    "        outer_loop = features(xs)\n",
    "        inner_loop = heads[a](outer_loop) # [15 (ways * shots), length of alphabet]\n",
    "        inner_loss = loss(inner_loop, ys)\n",
    "        total_loss += lambdas[a] * inner_loss\n",
    "        lambda_update[a] += inner_loss\n",
    "    total_loss.backward()\n",
    "    print(total_loss)\n",
    "    feature_optimizers.step()\n",
    "    lambdas = simplex_projection(lambdas + gamma * lambda_update)\n",
    "    # print(\"outer loop done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/minimario/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\nDeprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "xs, ys = sample_batch(10, 5)"
   ]
  }
 ]
}